{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Github Repositories\\self-corrective-rag-llamaindex\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from llama_index.core import (Settings,\n",
    "    SimpleDirectoryReader, Document,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.agent.react import ReActAgent\n",
    "from llama_index.core.workflow import (\n",
    "    step,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.postprocessor.rankGPT_rerank import RankGPTRerank\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the API keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'src.event_schema.HallucinationCheckerEvent'>\n",
      "<class 'src.event_schema.TransformQueryEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class 'src.event_schema.TransformQueryEvent'>\n",
      "<class 'src.event_schema.GenerateResponseEvent'>\n",
      "<class 'src.event_schema.GradeAnswerEvent'>\n",
      "<class 'src.event_schema.TransformQueryEvent'>\n",
      "<class 'src.event_schema.GradeDocsEvent'>\n",
      "<class 'src.event_schema.RetrieveEvent'>\n",
      "self_corrective_rag.html\n"
     ]
    }
   ],
   "source": [
    "from src.workflow import SelfCorrectiveRAG\n",
    "draw_all_possible_flows(SelfCorrectiveRAG, filename=\"self_corrective_rag.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step retrieve_docs\n",
      "---- retrieve_docs ----\n",
      "Loading existing index...\n",
      "docs: [NodeWithScore(node=TextNode(id_='a5c12a6f-08d2-47e5-ba40-eddf8c708bf3', embedding=None, metadata={'file_path': 'E:\\\\python projects\\\\self-corrective-rag-llamaindex\\\\data\\\\posts\\\\2023-03-15-prompt-engineering.html', 'file_name': '2023-03-15-prompt-engineering.html', 'file_type': 'text/html', 'file_size': 99181, 'creation_date': '2025-02-05', 'last_modified_date': '2025-02-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='06968492-0982-4526-b5bf-5a1ba47fcafb', node_type='4', metadata={'file_path': 'E:\\\\python projects\\\\self-corrective-rag-llamaindex\\\\data\\\\posts\\\\2023-03-15-prompt-engineering.html', 'file_name': '2023-03-15-prompt-engineering.html', 'file_type': 'text/html', 'file_size': 99181, 'creation_date': '2025-02-05', 'last_modified_date': '2025-02-05'}, hash='41392dae217b7b94bf308dfa1e21b705fbabbbc424f11ffe5b2e9716eaf68b59'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1d1e355e-6fab-4fd4-abe1-876fe28639fa', node_type='1', metadata={'file_path': 'E:\\\\python projects\\\\self-corrective-rag-llamaindex\\\\data\\\\posts\\\\2023-03-15-prompt-engineering.html', 'file_name': '2023-03-15-prompt-engineering.html', 'file_type': 'text/html', 'file_size': 99181, 'creation_date': '2025-02-05', 'last_modified_date': '2025-02-05'}, hash='6381ed682588bf57a59d5a4245d8efb72ee213a66e9dd65a7bf29a9f76aa39e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='8e18dc48-3a98-4871-a3fe-e7652119c1fe', node_type='1', metadata={}, hash='488bf4c46d8f28a7cf2b15ced149292611aea05c9e6e27e587ae1a2072ac0e28')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='<a href=\"https://arxiv.org/abs/2201.11903\">&ldquo;Chain of thought prompting elicits reasoning in large language models.&rdquo;</a> NeurIPS 2022</p>\\r\\n<p>[8] Wang et al. <a href=\"https://arxiv.org/abs/2203.11171\">&ldquo;Self-Consistency Improves Chain of Thought Reasoning in Language Models.&rdquo;</a> ICLR 2023.</p>\\r\\n<p>[9] Diao et al. <a href=\"https://arxiv.org/abs/2302.12246\">&ldquo;Active Prompting with Chain-of-Thought for Large Language Models.&rdquo;</a> arXiv preprint arXiv:2302.12246 (2023).</p>\\r\\n<p>[10] Zelikman et al.', mimetype='text/plain', start_char_idx=81189, end_char_idx=81722, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8071191682515363), NodeWithScore(node=TextNode(id_='c6796413-aa89-491d-b189-88368b964568', embedding=None, metadata={'file_path': 'E:\\\\python projects\\\\self-corrective-rag-llamaindex\\\\data\\\\posts\\\\2023-03-15-prompt-engineering.html', 'file_name': '2023-03-15-prompt-engineering.html', 'file_type': 'text/html', 'file_size': 99181, 'creation_date': '2025-02-05', 'last_modified_date': '2025-02-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='06968492-0982-4526-b5bf-5a1ba47fcafb', node_type='4', metadata={'file_path': 'E:\\\\python projects\\\\self-corrective-rag-llamaindex\\\\data\\\\posts\\\\2023-03-15-prompt-engineering.html', 'file_name': '2023-03-15-prompt-engineering.html', 'file_type': 'text/html', 'file_size': 99181, 'creation_date': '2025-02-05', 'last_modified_date': '2025-02-05'}, hash='41392dae217b7b94bf308dfa1e21b705fbabbbc424f11ffe5b2e9716eaf68b59'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ecf7fd95-f209-4e4e-a390-85f1f8d5bbbb', node_type='1', metadata={'file_path': 'E:\\\\python projects\\\\self-corrective-rag-llamaindex\\\\data\\\\posts\\\\2023-03-15-prompt-engineering.html', 'file_name': '2023-03-15-prompt-engineering.html', 'file_type': 'text/html', 'file_size': 99181, 'creation_date': '2025-02-05', 'last_modified_date': '2025-02-05'}, hash='594d1e3fbf6d2aa4e78e3e4f6731ad43986dcdfd2207e49e328ea1c90f7fdb3d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='792126c5-be91-426a-8ee4-9b368616ddc8', node_type='1', metadata={}, hash='55af6dbaded08135fae8aeeaf4327a8624a26d5c158b3a197e0719edf6ff98ca')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='“Self-Consistency Improves Chain of Thought Reasoning in Language Models.” ICLR 2023.\\\\n[9] Diao et al. “Active Prompting with Chain-of-Thought for Large Language Models.” arXiv preprint arXiv:2302.12246 (2023).\\\\n[10] Zelikman et al. “STaR: Bootstrapping Reasoning With Reasoning.” arXiv preprint arXiv:2203.14465 (2022).\\\\n[11] Ye \\\\u0026 Durrett. “The unreliability of explanations in few-shot in-context learning.” arXiv preprint arXiv:2205.03401 (2022).\\\\n[12] Trivedi et al. “Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.” arXiv preprint arXiv:2212.10509 (2022).\\\\n[13] Press et al.', mimetype='text/plain', start_char_idx=34384, end_char_idx=35021, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.78292250368331)]\n",
      "\n",
      "Step retrieve_docs produced event GradeDocsEvent\n",
      "Running step grade_docs\n",
      "---- grade_docs ----\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "doc string: <a href=\"https://arxiv.org/abs/2201.11903\">&ldquo;Chain of thought prompting elicits reasoning in large language models.&rdquo;</a> NeurIPS 2022</p>\n",
      "<p>[8] Wang et al. <a href=\"https://arxiv.org/abs/2203.11171\">&ldquo;Self-Consistency Improves Chain of Thought Reasoning in Language Models.&rdquo;</a> ICLR 2023.</p>\n",
      "<p>[9] Diao et al. <a href=\"https://arxiv.org/abs/2302.12246\">&ldquo;Active Prompting with Chain-of-Thought for Large Language Models.&rdquo;</a> arXiv preprint arXiv:2302.12246 (2023).</p>\n",
      "<p>[10] Zelikman et al.\n",
      "\n",
      "“Self-Consistency Improves Chain of Thought Reasoning in Language Models.” ICLR 2023.\\n[9] Diao et al. “Active Prompting with Chain-of-Thought for Large Language Models.” arXiv preprint arXiv:2302.12246 (2023).\\n[10] Zelikman et al. “STaR: Bootstrapping Reasoning With Reasoning.” arXiv preprint arXiv:2203.14465 (2022).\\n[11] Ye \\u0026 Durrett. “The unreliability of explanations in few-shot in-context learning.” arXiv preprint arXiv:2205.03401 (2022).\\n[12] Trivedi et al. “Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.” arXiv preprint arXiv:2212.10509 (2022).\\n[13] Press et al.\n",
      "Step grade_docs produced event GenerateResponseEvent\n",
      "Running step generate_response\n",
      "---- generate_response ----\n",
      "RAG PROMPT: input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n",
      "Generated response: Chain of thought prompting is a technique that elicits reasoning in large language models by providing a prompt that guides the model to generate a step-by-step thought process to arrive at an answer. This approach helps the model to break down complex problems into simpler, more manageable steps, and can improve its ability to reason and solve multi-step problems. The exact mechanism of chain of thought prompting is not fully explained in the provided context, but it appears to involve generating a series of intermediate steps or thoughts that lead to a final answer.\n",
      "Step generate_response produced event HallucinationCheckerEvent\n",
      "Running step hallucination_checker\n",
      "---- hallucination_checker ----\n",
      "PROMPT: input_variables=['answer', 'documents'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a grader evaluating whether an LLM's response is strictly based on and supported by a given set of retrieved facts.\\nAssign a binary score of 'yes' or 'no.'\\n'No' means the response is fully grounded in the provided facts, with no additional information beyond reasonable rewording.\\n'Yes' means the response includes hallucinations, contradicts the facts, or introduces information not explicitly present in the retrieved facts.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['answer', 'documents'], input_types={}, partial_variables={}, template='Set of facts: \\n\\n {documents} \\n\\n LLM generation: {answer}'), additional_kwargs={})]\n",
      "documents: <a href=\"https://arxiv.org/abs/2201.11903\">&ldquo;Chain of thought prompting elicits reasoning in large language models.&rdquo;</a> NeurIPS 2022</p>\n",
      "<p>[8] Wang et al. <a href=\"https://arxiv.org/abs/2203.11171\">&ldquo;Self-Consistency Improves Chain of Thought Reasoning in Language Models.&rdquo;</a> ICLR 2023.</p>\n",
      "<p>[9] Diao et al. <a href=\"https://arxiv.org/abs/2302.12246\">&ldquo;Active Prompting with Chain-of-Thought for Large Language Models.&rdquo;</a> arXiv preprint arXiv:2302.12246 (2023).</p>\n",
      "<p>[10] Zelikman et al.\n",
      "\n",
      "“Self-Consistency Improves Chain of Thought Reasoning in Language Models.” ICLR 2023.\\n[9] Diao et al. “Active Prompting with Chain-of-Thought for Large Language Models.” arXiv preprint arXiv:2302.12246 (2023).\\n[10] Zelikman et al. “STaR: Bootstrapping Reasoning With Reasoning.” arXiv preprint arXiv:2203.14465 (2022).\\n[11] Ye \\u0026 Durrett. “The unreliability of explanations in few-shot in-context learning.” arXiv preprint arXiv:2205.03401 (2022).\\n[12] Trivedi et al. “Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.” arXiv preprint arXiv:2212.10509 (2022).\\n[13] Press et al., answer: Chain of thought prompting is a technique that elicits reasoning in large language models by providing a prompt that guides the model to generate a step-by-step thought process to arrive at an answer. This approach helps the model to break down complex problems into simpler, more manageable steps, and can improve its ability to reason and solve multi-step problems. The exact mechanism of chain of thought prompting is not fully explained in the provided context, but it appears to involve generating a series of intermediate steps or thoughts that lead to a final answer.\n",
      "Hallucination Checker response: binary_score='no'\n",
      "Step hallucination_checker produced event GradeAnswerEvent\n",
      "Running step grade_answer\n",
      "---- grade_answer ----\n",
      "Answer Grader response: binary_score='yes'\n",
      "Step grade_answer produced event StopEvent\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "c = SelfCorrectiveRAG(timeout=120, verbose=True)\n",
    "result = await c.run(\n",
    "    query=\"Explain how chain of thought prompting works?\"\n",
    ")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
